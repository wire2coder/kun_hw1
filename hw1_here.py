# -*- coding: utf-8 -*-
"""hw1_here.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gzvQVO1dajr5HCuAtw6I1-aMKaVmRuYL
"""

# import stuff
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import csv
import math
import os
import timeit

# load CSV file
def load_csv(filename):
  dataset = []

  with open(filename, 'r') as file:
    next(file) # skip the first line ( the 'header' )
    csv_readder = csv.reader(file)
    
    for row in csv_readder:
      if not row:
        continue
      
      dataset.append(row)

  return dataset


# clear values in 'dictionary'
def clear_values_in_dic(dic1):
  dic1 = dic1.fromkeys(dic1, 0)
  # print('dic1.items() >>> ' , dic1.items() )

  return dic1  


# make a 'dictionary' from sentences
def convert_to_dic(dataset):
  dic1 = {}; # empty dictionary

  for row in dataset:
    # print(row[0].lower().split(" ") ) # row, 1st item, the sentence
    # print(row[1].lower().split(" ") ) # row, 2nd item, the 'answer'
    
    word_list = row[0].lower().split(" ")
    for word in word_list:
      # print(word)
      dic1[word] = 0

  return dic1


# convert from 'dictionary' to 'vector'
## input: [ ['I buy an apple phone', 'happy'], ['I eat the gig apple', 'happy'] ]
## 2 sentences go in, 2 vectors come out
def convert_sentences_to_vector(dic1, sentence_list):
  vector_list = []

  for idx, row in enumerate(sentence_list):
    dic1 = clear_values_in_dic(dic1)

    sentence = row[0].lower().split()
    answer = row[1].lower()
    # print(sentence)
    # print(answer)

    for word in sentence:
      # print(word)
      for key, value in dic1.items():
        # print(key)
        if (word == key):
          dic1[key] = 1
      
    # print( list( dic1.values() ) )
    vector_list.append( [list(dic1.values() ), answer ] )

  return vector_list



def predict_answer( test_row, train_dataset, k_nay ):
  my_naybers = find_naybers(test_row, train_dataset, k_nay)
  
  my_naybers_answer = [ row[-1] for row in my_naybers ] # >> [' ', 'happy', 'happy'], >> row[-1] the last 'column' in a row
  # print( my_naybers_answer )
  the_prediction = max( set(my_naybers_answer), key=my_naybers_answer.count ) # # set() math 'set' you don't have the same stuff in a 'set'
  # print( the_prediction )

  return the_prediction



def find_naybers(test_row, train_data, k_nay):
  distance_list = []

  for train_row in train_data:
    # eu_distance = calculate_eu_distance(test_row, train_row)
    man_distance = calculate_manhat_distance(test_row, train_row)
    # print(f"train_row: {train_row}")
    # print(f"train_row[1]: {train_row[1]}")
    distance_list.append( (man_distance, train_row[1]) )

  # print( distance_list )
  distance_list.sort( key=lambda asdf: asdf[0] ) # asdf[0] is just the 'first item (man distance)' in the 'distance_list'
  # print( distance_list )

  naybers = []
  for i in range(k_nay):
    naybers.append( distance_list[i] )

  return naybers


def calculate_manhat_distance(test_row, train_row):
  distance = 0.0

  # print(f"test_row: {test_row}  train_row: {train_row}")  
  print(f"test_row[0]: {test_row[0]}  train_row[0]: {train_row[0]}")  
  if ( len(test_row[0]) == len(train_row[0]) ):

    if (test_row[0] != train_row[0] ):

      for a, b in zip( test_row[0], train_row[0]  ):
        # print('calculate_manhat_distance a: ', a)
        # print('calculate_manhat_distance b: ', b)

        distance = distance + abs(a-b)
    else:
      print(f"\n *itself - itself")
      print(f"*skipped test_row[0]: {test_row[0]}  train_row[0]: {train_row[0]} \n")  

  else:
    print('ERROR, vector length do not match')
    
  return distance


v1 = [[2,3],'yes']
v2 = [[5,7],'no']
# v2 = [[5,8],'no'] # uncommit for error checking

dis1 = calculate_manhat_distance(v1, v2)
# print(f"checking v1 - v2 should be 7, got : {dis1}")

#if condition returns False, AssertionError is raised:
assert dis1 == 7, "v1 - v2 should be 7"



def calculate_eu_distance(test_row, train_row):
  distance = 0.0

  # print(f"test_row: {test_row}  train_row: {train_row}")  

  if ( len(test_row[0]) == len(train_row[0]) ):

    for a, b in zip( test_row[0], train_row[0] ):
      # print('calculate_eu_distance a: ', a)
      # print('calculate_eu_distance b: ', b)

      distance = distance + (a - b)**2
  else:
    print('ERROR, vector length do not match')
    # pass

  return math.sqrt( distance )



def accuracy_met(actual, predicted):
  correct = 0

  # print(f"actual {actual}")
  # print(f"predicted {predicted}")

  for idx in range( len(actual) ): # >> idx 0,1,2
    if actual[idx] == predicted[idx]:
      correct = correct + 1
  
  # print(f"correct: {correct}  out of total: { len(actual) } "  )
  # print( correct / float( len(actual) ) * 100 )
  return correct / float( len(actual) ) * 100
    


def k_eval(test_set, train_set, actual): 
  k_evaluation = []

  for k in range(1, 22, 3):
    preds = []

    for row in test_set:
      predictors_only = row[ : -1]
      prediction = predict_answer(predictors_only, train_set, k)

      preds.append( prediction ) 
    
    curr_accuracy = accuracy_met(actual, preds)
    k_evaluation.append( (k, curr_accuracy) )

  return k_evaluation

## this block of code below is for running 
## train_set.csv, validation_set.csv
## loading data
## why? to pick the value of 'k'

# getting file
filename_train_set_simple = '/content/drive/MyDrive/homework1 spring 2021/data/train_set_simple.csv'
print(f"filename: {filename_train_set_simple}")

# load csv file into a variable
train_set_simple = load_csv(filename_train_set_simple)
print(f"current train_set: {train_set_simple}")

# creating 'dict/ionary' from train_set.csv
train_set_dic = convert_to_dic(train_set_simple)
# print(f"train_set_dic.items() {train_set_dic.items()} "  )
# print(f"len( train_set_dic.items() ) {len( train_set_dic.items() )}")

# convert sentences into vectors
train_set_simple_vec = convert_sentences_to_vector(train_set_dic, train_set_simple)
# len( train_set_simple_vec[0][0] ) # >> should be 
# train_set_simple_vec[0][0] # >> should be the 'emotions'
# train_set_simple_vec[0][1] # >> should be the 'emotions'

actual_emotions = np.array(train_set_simple)[ : , -1] # >> use np.array() to get the 'emotions' from each sentence
# len( actual_emotions )
# print(f"actual_emotions {actual_emotions}")

## debugging block, here 2/18
# how to check if content inside 'list' are the same

## debug code
train_set = [ 
             [[1, 1, 1, 1, 1], 'happy'], 
              [[1, 0, 0, 1, 0], 'happy'],
              [[0, 0, 0, 1, 0], 'sad'],
             [[1, 1, 0, 1, 1], 'happy'] 
             ]

# train_set[1][0] == train_set[2][0]

for idx, row in enumerate(train_set):
  
  test_row = row
  print(f"test_row {test_row}")
  # print(f"row index: {idx}")
  

  prediction = predict_answer(test_row, train_set, 3)
  print(f"prediction: {prediction} \n")

## this block of code below is for running train_set.csv, validation_set.csv
## why? to pick the value of 'k'


## debug code
train_set = [ [[1, 1, 1, 1, 1], 'happy'], 
              [[1, 0, 0, 1, 0], 'happy'],
              [[0, 0, 0, 1, 0], 'sad'] ]

actual = np.array(train_set)[ : , -1]
print(f"actual {actual}")

# k_list = [3, 5, 7, 9, 11, 13, 15,17 ]
k_list = [3]

for k in k_list:
  preds3 = []

  print(f"\nlen train_set: { len(train_set) } ")
  print(f"len actual: { len(actual) } \n")
  start = timeit.default_timer() # start program timer

  for idx, row in enumerate(train_set): # how to check if content inside 'list' are the same
    test_row = row
    the_prediction = predict_answer(test_row, train_set, k)
    preds3.append( the_prediction )

  cur_accuracy = accuracy_met(actual, preds3)
  stop = timeit.default_timer() # stop program timer

  print(f"when K is {k}, accuracy %: {cur_accuracy}")
  print(f"program run time (seconds):  {stop - start} ")

## this block of code is for test_set.csv
## loading all the csv files
## final step, predicting answers


file_name_train_set = '/content/drive/MyDrive/homework1 spring 2021/data/train_set.csv'
# file_name = '/content/drive/MyDrive/homework1 spring 2021/data/validation_set.csv'
file_test_set_no_textid = '/content/drive/MyDrive/homework1 spring 2021/data/test_set_no_textid.csv'
file_name_for_making_dic = '/content/drive/MyDrive/homework1 spring 2021/data/train_vali_test_for_dic.csv'

dataset_to_make_dic = load_csv(file_name_for_making_dic)
# print(f"dataset1 {dataset1}")

# create 'dictionary' of words here
dic1 = convert_to_dic(dataset_to_make_dic)

print(f"file_name: {file_name_for_making_dic}")
print(f"dic1.items() {dic1.items()} "  )
print(f"len( dic1.items() ) {len( dic1.items() )}")

## this block of code is for test_set.csv
## loading all the csv files
## final step, predicting answers


# open train_set.csv file
train_set_file = load_csv(file_name_train_set)
# display(train_set_file)

# convert train_set.csv to vector, using dic1
train_set = convert_sentences_to_vector(dic1, train_set_file)
# len( train_set[0][0] ) >> should be 3,275
# train_set[0][1] >> should be the 'emotions'

# open test_set.csv file
test_set_file = load_csv(file_test_set_no_textid)
# display(test_set_file)

# convert test_set.csv to vector, using dic1
test_set = convert_sentences_to_vector(dic1, test_set_file)
# len( test_set[0][0] ) # >> should be 3,275
# test_set[0][1] # >>  should be the '' nothing

## this block of code is for test_set.csv
## the 'k' value will be 3
k_best = 3

print(f"len train_set: { len(train_set) } ")
print(f"len test_set: { len(test_set) } \n")


pred_final = []
start = timeit.default_timer() # start program timer


for idx, test_row in enumerate(test_set):
  the_prediction = predict_answer(test_row, train_set, k_best)
  pred_final.append( [the_prediction, idx] )  


stop = timeit.default_timer() # stop program timer
print(f"pred_final {pred_final}\n")
print(f"program run time (seconds):  {stop - start} ")

## this block of code is for
## writing the pred_final 'list' 
## into a csv file

dat1 = [ [ [1,2,3], 'yes'], [[4,5,6],'no'] ]

# open a csv file in 'w' mode
with open('111.csv', 'w', newline='') as file:
  write1 = csv.writer(file)
  write1.writerow( ['emotions', 'txtid'] )

  for item in pred_final:
    write1.writerow(item)

## backup code
##

k_start = 3
k_stop = math.floor ( math.sqrt( len(actual) ) )
print(f"k_start: { k_start } to k_stop: {k_stop} \n")
k_eval1 = []

for k in range(k_start, k_stop, 2): # 1 to 9, increment by 2 >> 1,3,5,7,9
  preds2 = []

  for row in train_set:
    the_prediction = predict_answer(row, train_set, k) # >> 'row' is the current row you use as a 'test_row'
    preds2.append( the_prediction )
  
  current_accuracy = accuracy_met(actual, preds2)
  k_eval1.append( (k, current_accuracy) )


print(f"number of K, accuracy: {k_eval1}")

## backup code
##

# test_row = [['My friend has an apple', '']]
# test_row_vector = convert_sentences_to_vector(dic1, test_row)
# print(test_row_vector)

# test_set = [ [[0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1], ''] ]
# test_row = [[0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1], ''] 

# train_row1 = [[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'happy']
# train_row2 = [[1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0], 'happy']
# train_row3 = [[0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0], 'sad']

# train_set = [ [[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'happy'], 
#               [[1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0], 'happy'],
#               [[0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0], 'sad'] ]
# calculate_eu_distance(test_row, train_row3)


# predict1 = predict_answer(test_row, train_dataset, 3)
# actual = ['happy', 'happy', 'sad']
# predicted = ['sad', 'happy', 'sad']